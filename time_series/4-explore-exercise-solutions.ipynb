{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Remember to document your thoughts and any takeaways as you work through visualizations! \n",
    "\n",
    "Using your store items data you prepped in lesson 2 exercises:\n",
    "\n",
    "1. Split your data into train and test using the sklearn.model_selection.TimeSeriesSplit method. \n",
    "1. Validate your splits by plotting X_train and y_train.  \n",
    "1. Plot the weekly average & the 7-day moving average. Compare the 2 plots. \n",
    "1. Plot the daily difference. Observe whether usage seems to vary drastically from day to day or has more of a smooth transition.   \n",
    "1. Plot a time series decomposition. \n",
    "1. Create a lag plot (day over day).  \n",
    "1. Run a lag correlation.   \n",
    "\n",
    "Using your OPS data you prepped in lesson 2 exercises: \n",
    "\n",
    "1. Split your data into train and test using the percent cutoff method.  \n",
    "1. Validate your splits by plotting X_train and y_train.  \n",
    "1. Plot the weekly average & the 7-day moving average. Compare the 2 plots. \n",
    "1. Group the electricity consumption time series by month of year, to explore annual seasonality.\n",
    "1. Plot the daily difference. Observe whether usage seems to vary drastically from day to day or has more of a smooth transition.   \n",
    "1. Plot a time series decomposition. Takeaways?   \n",
    "1. Create a lag plot (day over day).  \n",
    "1. Run a lag correlation.   \n",
    "\n",
    "If time: \n",
    "\n",
    "For each store I want to see how many items were sold over a period of time, for each item. Find a way to chart this. Hints: Subplots for the piece with the fewest distinct values (like store), x = time, y = count, color = item. If you have too many distinct items, you may need to plot the top n, while aggregating the others into an 'other' bucket.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "# data visualization \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_store_data_sql\n",
    "from prepare import prep_store_data\n",
    "\n",
    "df = get_store_data_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_store_data(df)\n",
    "target_vars = ['sale_amount','sales_total']\n",
    "df = df.resample('D')[target_vars].sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Item Sales\n",
    "\n",
    "### Q1\n",
    "#### Split your data into train and test using the sklearn.model_selection.TimeSeriesSplit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index to be row number\n",
    "df2 = df.reset_index()\n",
    "\n",
    "# create X and y\n",
    "X = df2.sale_date\n",
    "y = df2.sale_amount\n",
    "\n",
    "# create object, with 5 splits\n",
    "tss = TimeSeriesSplit(n_splits=5, max_train_size=None)\n",
    "\n",
    "# fit (get index values)\n",
    "# transform into X_train, X_test, y_train, y_test\n",
    "for train_index, test_index in tss.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Sara:\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "for train_index, test_index in tss.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_indices.append(train_index)\n",
    "    test_indices.append(test_index)\n",
    "train_indices[0]\n",
    "test_indices[0]\n",
    "\n",
    "\n",
    "for i in range(0,5):\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(X_train[train_indices[i]], y_train[train_indices[i]])\n",
    "    plt.plot(X[test_indices[i]], y[test_indices[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "#### Validate your splits by plotting X_train and y_train.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "plt.plot(X_train, y_train)\n",
    "plt.plot(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "#### Plot the weekly average & the 7-day moving average. Compare the 2 plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'sale_date': X_train, 'sale_amount': y_train}\n",
    "train = pd.DataFrame(data)\n",
    "train = train.groupby(['sale_date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_W = train.resample('W').mean()\n",
    "ax = train_W.plot(figsize = (12,4))\n",
    "ax.set_title('Item Sales: Weekly Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "ax = train.rolling(5).mean().plot(figsize=(12, 4))\n",
    "ax.set_title('Item Sales: 7-day Moving Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "#### Plot the daily difference. Observe whether usage seems to vary drastically from day to day or has more of a smooth transition.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.diff(periods=1).plot(figsize=(12, 4), linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "#### Plot a time series decomposition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(train.resample('W').mean(), model='additive')\n",
    "\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "#### Create a lag plot (day over day).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.lag_plot(train.resample('D').mean(), lag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7\n",
    "#### Run a lag correlation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.concat([train.shift(1), train], axis=1)\n",
    "df_corr.columns = ['t-1','t+1']\n",
    "result = df_corr.corr()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPS Data\n",
    "\n",
    "### Q1\n",
    "\n",
    "#### Split your data into train and test using the percent cutoff method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to datetime\n",
    "df['date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('date').resample('D').sum()\n",
    "\n",
    "# Set the train size to be 66% of total size of dataframe (# of rows).   \n",
    "# Compute how many rows that is.  \n",
    "train_size = int(len(df) * 0.66)\n",
    "\n",
    "# Select our data up to the index representing the 66th percentile as our 'train' sample.  \n",
    "# Select our data from the 66th percentile through the end of the dataframe as our 'test' sample.  \n",
    "\n",
    "train, test = df[0:train_size], df[train_size:len(df)]\n",
    "print('Observations: %d' % (len(df)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "#### Validate your splits by plotting X_train and y_train.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Consumption.plot(figsize=(12,4))\n",
    "test.Consumption.plot(figsize=(12,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "#### Plot the weekly average & the 7-day moving average. Compare the 2 plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.resample('W').mean().plot(figsize=(12, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rolling(7).mean().plot(figsize=(12, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "#### Group the electricity consumption time series by month of year, to explore annual seasonality.\n",
    "\n",
    "We will plot all 3 variables for fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the month column\n",
    "df['month'] = df.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(11, 10), sharex=True)\n",
    "for name, ax in zip(['Consumption', 'Solar', 'Wind'], axes):\n",
    "    sns.boxplot(data=df, x='month', y=name, ax=ax)\n",
    "    ax.set_ylabel('GWh')\n",
    "    ax.set_title(name)\n",
    "    if ax != axes[-1]:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "# Remove the automatic x-axis label from all but the bottom subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "#### Plot the daily difference. Observe whether usage seems to vary drastically from day to day or has more of a smooth transition.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.diff(periods=10).plot(figsize=(12, 4), alpha=0.7, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "#### Plot a time series decomposition. Takeaways?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(train.resample('W').mean(), model='additive')\n",
    "\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7\n",
    "#### Create a lag plot (day over day).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.lag_plot(train.Consumption, lag=1, c='red', alpha=0.5)\n",
    "pd.plotting.lag_plot(train.Wind, lag=1, c='orange', alpha=0.25)\n",
    "pd.plotting.lag_plot(train.Solar, lag=1, c='green', alpha=0.25)\n",
    "pd.plotting.lag_plot(train['Wind+Solar'], lag=1, c='blue', alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8\n",
    "#### Run a lag correlation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(train.columns):\n",
    "    df_corr = pd.concat([train[col].shift(1), train[col]], axis=1)\n",
    "    df_corr.columns = ['t-1','t+1']\n",
    "    result = df_corr.corr()\n",
    "    print(col,\":\\n\",result,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
