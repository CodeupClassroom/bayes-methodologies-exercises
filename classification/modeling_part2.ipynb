{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from prepare_notebook import prep_titanic\n",
    "from prepare_notebook import prep_titanic_unscaled_age\n",
    "from prepare_notebook import scale_titanic\n",
    "from prepare_notebook import prep_iris\n",
    "from acquire import get_iris_data\n",
    "from acquire import get_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df=prep_iris(get_iris_data())\n",
    "y=iris_df[['species']]\n",
    "X=iris_df[['petal_length','petal_width','sepal_length','sepal_width']]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=.7,random_state=123)\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "#1) Fit the Random Forest classifier to your training sample and transform(i.e. make predictions on the sample training)\n",
    "#setting the random_state accordingly and setting min_samples_leaf=1 and max_depth=20.\n",
    "rf=RandomForestClassifier(min_samples_leaf=1,max_depth=20)\n",
    "rf.fit(X_train,y_train)\n",
    "pred_default=rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "            setosa  versicolor  virginica\n",
      "setosa          32           0          0\n",
      "versicolor       0          40          0\n",
      "virginica        0           0         33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        40\n",
      "           2       1.00      1.00      1.00        33\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2)Evaluate your in-sample results using the model score,confusion matrix,and classification report.\n",
    "labels=sorted(list(iris_df.species_name.unique()))\n",
    "print(rf.score(X_train,y_train))\n",
    "print(pd.DataFrame(confusion_matrix(y_train,pred_default),index=labels,columns=labels))\n",
    "print(classification_report(y_train,pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Print and clearly label the following:Accuracy,true positive rate,false positive rate,true negative rate,false negative rate,\n",
    "# false negative rate,precision,recall,f1-score,and support. \n",
    "confusion_matrix1=pd.DataFrame(confusion_matrix(y_train,pred_default),index=labels,columns=labels)\n",
    "FP = confusion_matrix1.sum(axis=0) - np.diag(confusion_matrix1)  \n",
    "FN = confusion_matrix1.sum(axis=1) - np.diag(confusion_matrix1)\n",
    "TP = np.diag(confusion_matrix1)\n",
    "TN = confusion_matrix1.values.sum() - (FP + FN + TP)\n",
    "\n",
    "#True positive rate/recall\n",
    "TPR = TP/(TP+FN)\n",
    "# True negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# False positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "# F1-score\n",
    "f1_score=2*TP/(2*TP+FP+FN)\n",
    "\n",
    "#support\n",
    "support=len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "            setosa  versicolor  virginica\n",
      "setosa          32           0          0\n",
      "versicolor       0          40          0\n",
      "virginica        0           0         33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        40\n",
      "           2       1.00      1.00      1.00        33\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4)Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3\n",
    "rf_shallow=RandomForestClassifier(min_samples_leaf=5,max_depth=3)\n",
    "rf_shallow.fit(X_train,y_train)\n",
    "pred_shallow=rf.predict(X_train)\n",
    "\n",
    "print(rf.score(X_train,y_train))\n",
    "print(pd.DataFrame(confusion_matrix(y_train,pred_default),index=labels,columns=labels))\n",
    "print(classification_report(y_train,pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) What are the differences in the evaluation metrics? Which performs better on your in-sample data?\n",
    "#Why?\n",
    "\n",
    "#6) Save the best model in forest_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)Fit the K-Nearest Neighbors classifier to your training sample and transform\n",
    "#(make predictions on the training sample)\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "pred_default2=knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9809523809523809\n",
      "            setosa  versicolor  virginica\n",
      "setosa          32           0          0\n",
      "versicolor       0          39          1\n",
      "virginica        0           1         32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.97      0.97      0.97        40\n",
      "           2       0.97      0.97      0.97        33\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2)Evaluate your in-sample results using the model score,confusion matrix,and classification report.\n",
    "print(knn.score(X_train,y_train))\n",
    "print(pd.DataFrame(confusion_matrix(y_train,pred_default2),index=labels,columns=labels))\n",
    "print(classification_report(y_train,pred_default2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Print and clearly label the following:Accuracy,true positive rate,false positive rate,true negative rate,false negative rate,\n",
    "# false negative rate,precision,recall,f1-score,and support. \n",
    "#3) Print and clearly label the following:Accuracy,true positive rate,false positive rate,true negative rate,false negative rate,\n",
    "# false negative rate,precision,recall,f1-score,and support. \n",
    "confusion_matrix2=pd.DataFrame(confusion_matrix(y_train,pred_default2),index=labels,columns=labels)\n",
    "FP = confusion_matrix2.sum(axis=0) - np.diag(confusion_matrix2)  \n",
    "FN = confusion_matrix2.sum(axis=1) - np.diag(confusion_matrix2)\n",
    "TP = np.diag(confusion_matrix2)\n",
    "TN = confusion_matrix2.values.sum() - (FP + FN + TP)\n",
    "\n",
    "#True positive rate/recall\n",
    "TPR = TP/(TP+FN)\n",
    "# True negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# False positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "# F1-score\n",
    "f1_score=2*TP/(2*TP+FP+FN)\n",
    "\n",
    "#support\n",
    "support=len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714285714285714\n",
      "            setosa  versicolor  virginica\n",
      "setosa          32           0          0\n",
      "versicolor       0          39          1\n",
      "virginica        0           2         31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        40\n",
      "           2       0.97      0.94      0.95        33\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       105\n",
      "   macro avg       0.97      0.97      0.97       105\n",
      "weighted avg       0.97      0.97      0.97       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4)Run through steps 2-4 setting k=10\n",
    "knn_10=KNeighborsClassifier(n_neighbors=10)\n",
    "knn_10.fit(X_train,y_train)\n",
    "pred_10=knn_10.predict(X_train)\n",
    "\n",
    "\n",
    "print(knn_10.score(X_train,y_train))\n",
    "print(pd.DataFrame(confusion_matrix(y_train,pred_10),index=labels,columns=labels))\n",
    "print(classification_report(y_train,pred_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9619047619047619\n",
      "            setosa  versicolor  virginica\n",
      "setosa          32           0          0\n",
      "versicolor       0          39          1\n",
      "virginica        0           3         30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.93      0.97      0.95        40\n",
      "           2       0.97      0.91      0.94        33\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       105\n",
      "   macro avg       0.97      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5)Run through steps 2-4 setting k=20\n",
    "knn_20=KNeighborsClassifier(n_neighbors=20)\n",
    "knn_20.fit(X_train,y_train)\n",
    "pred_20=knn_20.predict(X_train)\n",
    "\n",
    "print(knn_20.score(X_train,y_train))\n",
    "print(pd.DataFrame(confusion_matrix(y_train,pred_20),index=labels,columns=labels))\n",
    "print(classification_report(y_train,pred_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) What are the differences in the evaluation metrics? Which performs better on your in-sample\n",
    "#data? Why?\n",
    "\n",
    "#7) Save the best model in `knn_fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.843687374749499\n",
      "          survived  died\n",
      "survived       266    27\n",
      "died            51   155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       293\n",
      "           1       0.85      0.75      0.80       206\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       499\n",
      "   macro avg       0.85      0.83      0.84       499\n",
      "weighted avg       0.84      0.84      0.84       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering\n",
    "#Titanic Data\n",
    "#Create a feature named who, this should be either man, woman, or child. How does including this feature affect your model's performance?\n",
    "titanic_df=prep_titanic_unscaled_age(get_titanic_data())\n",
    "titanic_df.dropna(inplace=True)\n",
    "titanic_df['who'] = np.where(titanic_df['age']<18, 'child', np.where(titanic_df['sex']=='male','man','woman'))\n",
    "titanic_df['adult_male']=np.where((titanic_df['age']>=18) & (titanic_df['sex']=='male') ,1,0)\n",
    "\n",
    "\n",
    "#encode the values in who\n",
    "encoder_titanic=LabelEncoder()\n",
    "encoder_titanic.fit(titanic_df.who)\n",
    "titanic_df['who']=encoder_titanic.transform(titanic_df.who)\n",
    "\n",
    "#scale age and fare columns and drop some `sex`,`embark_town`,`class`,and target\n",
    "titanic_df=scale_titanic(titanic_df)\n",
    "y=titanic_df[['survived']]\n",
    "X=titanic_df.drop(columns=['survived','sex','embark_town','class','passenger_id','adult_male'])\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=.7,random_state=123)\n",
    "\n",
    "knn_who=KNeighborsClassifier()\n",
    "knn_who.fit(X_train,y_train)\n",
    "who_predictions=knn_who.predict(X_train)\n",
    "labels=['survived','died']\n",
    "print(knn_who.score(X_train,y_train))\n",
    "print(pd.DataFrame(confusion_matrix(y_train,who_predictions),index=labels,columns=labels))\n",
    "print(classification_report(y_train,who_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7615230460921844\n",
      "          survived  died\n",
      "survived       273    20\n",
      "died            99   107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       293\n",
      "           1       0.84      0.52      0.64       206\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       499\n",
      "   macro avg       0.79      0.73      0.73       499\n",
      "weighted avg       0.78      0.76      0.75       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a feature named adult_male that is either a 1 or a 0. How does this affect your model's predictions?\n",
    "#titanic_df['adult_male']=np.where((titanic_df['age']>=18) & (titanic_df['sex']=='male') ,1,0)\n",
    "y=titanic_df[['survived']]\n",
    "X=titanic_df.drop(columns=['survived','sex','embark_town','class','passenger_id','who'])\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=.7,random_state=123)\n",
    "knn_male=KNeighborsClassifier()\n",
    "knn_male.fit(X_train,y_train)\n",
    "male_predictions=knn_who.predict(X_train)\n",
    "labels=['survived','died']\n",
    "print(knn_who.score(X_train,y_train))\n",
    "print(pd.DataFrame(confusion_matrix(y_train,male_predictions),index=labels,columns=labels))\n",
    "print(classification_report(y_train,male_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris Data\n",
    "#Create features named petal_area and sepal_area.\n",
    "iris_df['petal_area']=iris_df['petal_length']*iris_df['petal_width']\n",
    "iris_df['sepal_area']=iris_df['sepal_length']*iris_df['sepal_width']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
