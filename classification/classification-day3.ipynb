{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "\n",
    "import acquire\n",
    "from prepare import split, impute, encode, scale_minmax, prepare\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['passenger_id','embarked','deck'], inplace=True)\n",
    "df.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many missing values are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "class            0\n",
       "embark_town      2\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Age** There are 177/891 observations missing an age value. I'm not sure if it would be safe to impute here with a single value. I may need to split into child and adult before imputing, but I will likely go with median if I impute at all, and either way. i.e. am I going to fit the impute function on entire set or on sub-groups. \n",
    "- **Task:** Create a impute median function\n",
    "\n",
    "- **Embark_town** I see only 2 in embark_town, so I can safely impute here...let's see the best method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Southampton    644\n",
       "Cherbourg      168\n",
       "Queenstown      77\n",
       "NaN              2\n",
       "Name: embark_town, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embark_town.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: We should use the 'mode' or most frequent value to impute here, given that the vast majority come from Southamption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size=.80, stratify=df.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build impute function to impute the mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mode(train, test, column_list):\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    train[column_list] = imputer.fit_transform(train[column_list])\n",
    "    test[column_list] = imputer.transform(test[column_list])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function on embark_town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = impute_mode(train, test, column_list = ['embark_town'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify missing values were filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train.embark_town.isnull().sum() + test.embark_town.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the impute_median function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_median(train, test, column_list):\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train[column_list] = imputer.fit_transform(train[column_list])\n",
    "    test[column_list] = imputer.transform(test[column_list])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge these 2 functions into a single function where strategy is an argument of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(train, test, my_strategy, column_list):\n",
    "    imputer = SimpleImputer(strategy=my_strategy)\n",
    "    train[column_list] = imputer.fit_transform(train[column_list])\n",
    "    test[column_list] = imputer.transform(test[column_list])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = impute(train, test, my_strategy = 'most_frequent', column_list = ['embark_town'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2 = impute(train, test, my_strategy = 'median', column_list = ['age'])\n",
    "t1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train, test, col_name):\n",
    "    \n",
    "    encoded_values = sorted(list(train[col_name].unique()))\n",
    "    \n",
    "    # Integer Encoding\n",
    "    int_encoder = LabelEncoder()\n",
    "    train.encoded = int_encoder.fit_transform(train[col_name])\n",
    "    test.encoded = int_encoder.transform(test[col_name])\n",
    "    \n",
    "    # create 2D np arrays of the encoded variable (in train and test)\n",
    "    train_array = np.array(train.encoded).reshape(len(train.encoded),1)\n",
    "    test_array = np.array(test.encoded).reshape(len(test.encoded),1)\n",
    "\n",
    "    # One Hot Encoding\n",
    "    ohe = OneHotEncoder(sparse=False, categories='auto')\n",
    "    train_ohe = ohe.fit_transform(train_array)\n",
    "    test_ohe = ohe.transform(test_array)\n",
    "    \n",
    "    # Turn the array of new values into a data frame with columns names being the values\n",
    "    # and index matching that of train/test\n",
    "    # then merge the new dataframe with the existing train/test dataframe\n",
    "    train_encoded = pd.DataFrame(data=train_ohe,\n",
    "                            columns=encoded_values, index=train.index)\n",
    "    train = train.join(train_encoded)\n",
    "    \n",
    "    test_encoded = pd.DataFrame(data=test_ohe,\n",
    "                               columns=encoded_values, index=test.index)\n",
    "    test = test.join(test_encoded)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = encode(train, test, 'class')\n",
    "train, test = encode(train, test, 'embark_town')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_minmax(train, test, column_list):\n",
    "    scaler = MinMaxScaler()\n",
    "    column_list_scaled = [col + '_scaled' for col in column_list]\n",
    "    train_scaled = pd.DataFrame(scaler.fit_transform(train[column_list]), \n",
    "                                columns = column_list_scaled, \n",
    "                                index = train.index)\n",
    "    train = train.join(train_scaled)\n",
    "\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test[column_list]), \n",
    "                                columns = column_list_scaled, \n",
    "                                index = test.index)\n",
    "    test = test.join(test_scaled)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['age', 'fare']\n",
    "train, test = scale_minmax(train, test, columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train, test, imputer, int_encoder, ohe, scaler = \\\n",
    "    prepare(df, drop_cols = ['passenger_id','embarked','deck'], \n",
    "            target = 'survived', train_prop=.80, seed=123, \n",
    "            impute_cols = ['embark_town'], impute_strategy='most_frequent',\n",
    "            encode_col = 'embark_town', scale_cols = ['age','fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "### T-Test\n",
    "#### Is age a driver of survival?\n",
    "Use a t-test to compare the age of those who survived vs. those who did not.\n",
    "Is there a significant difference? That is, is the average age of those who survived significantly different from those who did not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.ttest_ind(\n",
    "    train[train.survived == 1].age.dropna(),\n",
    "    train[train.survived == 0].age.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the results of my t-test affected if I use the scaled values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.ttest_ind(\n",
    "    train[train.survived == 1].age_scaled.dropna(),\n",
    "    train[train.survived == 0].age_scaled.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Should I fill missing values in Age? \n",
    "\n",
    "Use the t-test to help decide...\n",
    "\n",
    "When filling missing values in age with the median...does it make a difference? \n",
    "Should I fill that many missing values with a single value?\n",
    "By comparing the results of the t-test we can see it does make a difference. \n",
    "This t-test turns out to not be significant due to the elevation of ages of some number of children being given an age of the median of all ages (32 years old +/-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = impute(train, test, my_strategy='median', column_list = ['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.ttest_ind(\n",
    "    train[train.survived == 1].age.dropna(),\n",
    "    train[train.survived == 0].age.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared: Comparing 2 categorical variables\n",
    "\n",
    "#### Is the location of embarkment a driver of survival? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.embark_town, train.survived)\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, degf, expected = sp.stats.chi2_contingency(observed)\n",
    "print('chi2: ', chi2)\n",
    "print('p-value: ', p)\n",
    "print('degrees of freedom', degf)\n",
    "print('expected values\\n', expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function you defined in acquire.py to load the titanic data set.\n",
    "Remove the deck (too many nulls) and embarked (directly correlated with embark_town) columns\n",
    "Fill missing values with np.nan\n",
    "Split data into test and train\n",
    "Create a new column, is_child\n",
    "Handle the missing values in embark_town by using the SimpleImputer\n",
    "Handle the missing values in age by using the SimpleImputer\n",
    "Use LabelEncoder to transform the sex column to integer encoded\n",
    "Use OneHotEncoder to transform the sex column to one hot encoded\n",
    "Scale age and fare using MinMaxScaler\n",
    "Create a function named prep_titanic that accepts the untransformed titanic data, and returns the data with the transformations above applied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
