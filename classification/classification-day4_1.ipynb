{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#modeling imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#pipeline modules\n",
    "from acquire import get_titanic_data\n",
    "from prepare_notebook import prep_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id    0\n",
       "survived        0\n",
       "pclass          0\n",
       "sex             0\n",
       "age             0\n",
       "sibsp           0\n",
       "parch           0\n",
       "fare            0\n",
       "embarked        0\n",
       "class           0\n",
       "embark_town     0\n",
       "alone           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=prep_titanic(get_titanic_data())\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3</td>\n",
       "      <td>0.032420</td>\n",
       "      <td>0.031035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3</td>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>0.723549</td>\n",
       "      <td>0.285990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass       age      fare  sibsp  parch\n",
       "60        3  0.271174  0.014110      0      0\n",
       "348       3  0.032420  0.031035      1      1\n",
       "606       3  0.371701  0.015412      0      0\n",
       "195       1  0.723549  0.285990      0      0\n",
       "56        2  0.258608  0.020495      0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df[['pclass','age','fare','sibsp','parch']]\n",
    "y=df[['survived']]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=123)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={1: 2}, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit=LogisticRegression(C=1,class_weight={1:2},random_state=123,solver='saga')\n",
    "logit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.06836414 -1.9727291   0.79910148 -0.27300495  0.40904858]]\n",
      "Intercept: \n",
      " [3.3184823]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6011566 , 0.3988434 ],\n",
       "       [0.44762357, 0.55237643],\n",
       "       [0.64738422, 0.35261578],\n",
       "       [0.25897796, 0.74102204],\n",
       "       [0.33448517, 0.66551483],\n",
       "       [0.58294606, 0.41705394],\n",
       "       [0.60685253, 0.39314747],\n",
       "       [0.19441232, 0.80558768],\n",
       "       [0.17362731, 0.82637269],\n",
       "       [0.52455931, 0.47544069],\n",
       "       [0.16247945, 0.83752055],\n",
       "       [0.58295236, 0.41704764],\n",
       "       [0.15087653, 0.84912347],\n",
       "       [0.58119018, 0.41880982],\n",
       "       [0.37698269, 0.62301731],\n",
       "       [0.59260952, 0.40739048],\n",
       "       [0.44364017, 0.55635983],\n",
       "       [0.63722058, 0.36277942],\n",
       "       [0.63909002, 0.36090998],\n",
       "       [0.06179714, 0.93820286],\n",
       "       [0.29721402, 0.70278598],\n",
       "       [0.38490873, 0.61509127],\n",
       "       [0.51995819, 0.48004181],\n",
       "       [0.60682618, 0.39317382],\n",
       "       [0.6008496 , 0.3991504 ],\n",
       "       [0.6127725 , 0.3872275 ],\n",
       "       [0.35601313, 0.64398687],\n",
       "       [0.33547693, 0.66452307],\n",
       "       [0.07865925, 0.92134075],\n",
       "       [0.64761412, 0.35238588],\n",
       "       [0.51457738, 0.48542262],\n",
       "       [0.31297827, 0.68702173],\n",
       "       [0.50811418, 0.49188582],\n",
       "       [0.24317615, 0.75682385],\n",
       "       [0.57055227, 0.42944773],\n",
       "       [0.21251094, 0.78748906],\n",
       "       [0.64747279, 0.35252721],\n",
       "       [0.28607298, 0.71392702],\n",
       "       [0.05571604, 0.94428396],\n",
       "       [0.35035025, 0.64964975],\n",
       "       [0.21943545, 0.78056455],\n",
       "       [0.66416903, 0.33583097],\n",
       "       [0.68799477, 0.31200523],\n",
       "       [0.6636107 , 0.3363893 ],\n",
       "       [0.40863589, 0.59136411],\n",
       "       [0.67239424, 0.32760576],\n",
       "       [0.61744535, 0.38255465],\n",
       "       [0.14895747, 0.85104253],\n",
       "       [0.66446571, 0.33553429],\n",
       "       [0.4858876 , 0.5141124 ],\n",
       "       [0.52627536, 0.47372464],\n",
       "       [0.58299187, 0.41700813],\n",
       "       [0.70192884, 0.29807116],\n",
       "       [0.59496341, 0.40503659],\n",
       "       [0.31780102, 0.68219898],\n",
       "       [0.75099888, 0.24900112],\n",
       "       [0.08156433, 0.91843567],\n",
       "       [0.63540612, 0.36459388],\n",
       "       [0.15851973, 0.84148027],\n",
       "       [0.2121195 , 0.7878805 ],\n",
       "       [0.49517193, 0.50482807],\n",
       "       [0.19186506, 0.80813494],\n",
       "       [0.51073203, 0.48926797],\n",
       "       [0.59042566, 0.40957434],\n",
       "       [0.72700561, 0.27299439],\n",
       "       [0.52921723, 0.47078277],\n",
       "       [0.60018076, 0.39981924],\n",
       "       [0.24766808, 0.75233192],\n",
       "       [0.61694665, 0.38305335],\n",
       "       [0.65306486, 0.34693514],\n",
       "       [0.39079417, 0.60920583],\n",
       "       [0.63068687, 0.36931313],\n",
       "       [0.69151129, 0.30848871],\n",
       "       [0.6063423 , 0.3936577 ],\n",
       "       [0.12638884, 0.87361116],\n",
       "       [0.23389907, 0.76610093],\n",
       "       [0.57734335, 0.42265665],\n",
       "       [0.14508558, 0.85491442],\n",
       "       [0.44008296, 0.55991704],\n",
       "       [0.08149023, 0.91850977],\n",
       "       [0.58338049, 0.41661951],\n",
       "       [0.14944068, 0.85055932],\n",
       "       [0.21210194, 0.78789806],\n",
       "       [0.47275691, 0.52724309],\n",
       "       [0.379975  , 0.620025  ],\n",
       "       [0.04656622, 0.95343378],\n",
       "       [0.38201994, 0.61798006],\n",
       "       [0.75545019, 0.24454981],\n",
       "       [0.59360923, 0.40639077],\n",
       "       [0.62132841, 0.37867159],\n",
       "       [0.60090728, 0.39909272],\n",
       "       [0.64113542, 0.35886458],\n",
       "       [0.43390464, 0.56609536],\n",
       "       [0.23462469, 0.76537531],\n",
       "       [0.22378298, 0.77621702],\n",
       "       [0.12711419, 0.87288581],\n",
       "       [0.50675477, 0.49324523],\n",
       "       [0.5077294 , 0.4922706 ],\n",
       "       [0.58288759, 0.41711241],\n",
       "       [0.16043263, 0.83956737],\n",
       "       [0.06625198, 0.93374802],\n",
       "       [0.70428135, 0.29571865],\n",
       "       [0.18226721, 0.81773279],\n",
       "       [0.1699095 , 0.8300905 ],\n",
       "       [0.34472924, 0.65527076],\n",
       "       [0.17450559, 0.82549441],\n",
       "       [0.25231586, 0.74768414],\n",
       "       [0.56425549, 0.43574451],\n",
       "       [0.44023158, 0.55976842],\n",
       "       [0.70170989, 0.29829011],\n",
       "       [0.1649566 , 0.8350434 ],\n",
       "       [0.17116376, 0.82883624],\n",
       "       [0.21106166, 0.78893834],\n",
       "       [0.59488981, 0.40511019],\n",
       "       [0.42066871, 0.57933129],\n",
       "       [0.41581375, 0.58418625],\n",
       "       [0.677252  , 0.322748  ],\n",
       "       [0.47275691, 0.52724309],\n",
       "       [0.16592488, 0.83407512],\n",
       "       [0.317294  , 0.682706  ],\n",
       "       [0.60104754, 0.39895246],\n",
       "       [0.15304735, 0.84695265],\n",
       "       [0.2258726 , 0.7741274 ],\n",
       "       [0.2482564 , 0.7517436 ],\n",
       "       [0.48487432, 0.51512568],\n",
       "       [0.58288759, 0.41711241],\n",
       "       [0.13553372, 0.86446628],\n",
       "       [0.35035954, 0.64964046],\n",
       "       [0.5804396 , 0.4195604 ],\n",
       "       [0.66421105, 0.33578895],\n",
       "       [0.65845383, 0.34154617],\n",
       "       [0.45863117, 0.54136883],\n",
       "       [0.26357247, 0.73642753],\n",
       "       [0.2474877 , 0.7525123 ],\n",
       "       [0.18676587, 0.81323413],\n",
       "       [0.07616386, 0.92383614],\n",
       "       [0.35123828, 0.64876172],\n",
       "       [0.59243052, 0.40756948],\n",
       "       [0.64137476, 0.35862524],\n",
       "       [0.58897586, 0.41102414],\n",
       "       [0.43279653, 0.56720347],\n",
       "       [0.65301185, 0.34698815],\n",
       "       [0.388263  , 0.611737  ],\n",
       "       [0.2109541 , 0.7890459 ],\n",
       "       [0.61102134, 0.38897866],\n",
       "       [0.62443224, 0.37556776],\n",
       "       [0.57695318, 0.42304682],\n",
       "       [0.48937377, 0.51062623],\n",
       "       [0.15671878, 0.84328122],\n",
       "       [0.38490873, 0.61509127],\n",
       "       [0.6363642 , 0.3636358 ],\n",
       "       [0.35085809, 0.64914191],\n",
       "       [0.60096182, 0.39903818],\n",
       "       [0.66535872, 0.33464128],\n",
       "       [0.64732931, 0.35267069],\n",
       "       [0.36843484, 0.63156516],\n",
       "       [0.67015841, 0.32984159],\n",
       "       [0.29343751, 0.70656249],\n",
       "       [0.33389092, 0.66610908],\n",
       "       [0.30253583, 0.69746417],\n",
       "       [0.31301896, 0.68698104],\n",
       "       [0.10047055, 0.89952945],\n",
       "       [0.27995343, 0.72004657],\n",
       "       [0.63022756, 0.36977244],\n",
       "       [0.57694526, 0.42305474],\n",
       "       [0.74139236, 0.25860764],\n",
       "       [0.17371873, 0.82628127],\n",
       "       [0.63657504, 0.36342496],\n",
       "       [0.53765826, 0.46234174],\n",
       "       [0.316267  , 0.683733  ],\n",
       "       [0.18096053, 0.81903947],\n",
       "       [0.16262952, 0.83737048],\n",
       "       [0.78443182, 0.21556818],\n",
       "       [0.66962234, 0.33037766],\n",
       "       [0.69937369, 0.30062631],\n",
       "       [0.43692881, 0.56307119],\n",
       "       [0.36918324, 0.63081676],\n",
       "       [0.21191024, 0.78808976],\n",
       "       [0.60115817, 0.39884183],\n",
       "       [0.13989239, 0.86010761],\n",
       "       [0.3691032 , 0.6308968 ],\n",
       "       [0.73389545, 0.26610455],\n",
       "       [0.37323979, 0.62676021],\n",
       "       [0.57514441, 0.42485559],\n",
       "       [0.58364933, 0.41635067],\n",
       "       [0.2128279 , 0.7871721 ],\n",
       "       [0.23389907, 0.76610093],\n",
       "       [0.7344586 , 0.2655414 ],\n",
       "       [0.67513593, 0.32486407],\n",
       "       [0.34472924, 0.65527076],\n",
       "       [0.11474226, 0.88525774],\n",
       "       [0.64112942, 0.35887058],\n",
       "       [0.59498378, 0.40501622],\n",
       "       [0.61865776, 0.38134224],\n",
       "       [0.63012789, 0.36987211],\n",
       "       [0.58822365, 0.41177635],\n",
       "       [0.65866864, 0.34133136],\n",
       "       [0.62043987, 0.37956013],\n",
       "       [0.05971198, 0.94028802],\n",
       "       [0.42801521, 0.57198479],\n",
       "       [0.19242697, 0.80757303],\n",
       "       [0.29058824, 0.70941176],\n",
       "       [0.18022179, 0.81977821],\n",
       "       [0.68534534, 0.31465466],\n",
       "       [0.5949368 , 0.4050632 ],\n",
       "       [0.27328102, 0.72671898],\n",
       "       [0.63340355, 0.36659645],\n",
       "       [0.09885604, 0.90114396],\n",
       "       [0.68322054, 0.31677946],\n",
       "       [0.22889044, 0.77110956],\n",
       "       [0.66752761, 0.33247239],\n",
       "       [0.65861751, 0.34138249],\n",
       "       [0.6221062 , 0.3778938 ],\n",
       "       [0.39968176, 0.60031824],\n",
       "       [0.60528804, 0.39471196],\n",
       "       [0.34472924, 0.65527076],\n",
       "       [0.37763697, 0.62236303],\n",
       "       [0.79035227, 0.20964773],\n",
       "       [0.26521046, 0.73478954],\n",
       "       [0.32064507, 0.67935493],\n",
       "       [0.23926443, 0.76073557],\n",
       "       [0.35601313, 0.64398687],\n",
       "       [0.55860785, 0.44139215],\n",
       "       [0.69853678, 0.30146322],\n",
       "       [0.17018274, 0.82981726],\n",
       "       [0.50042848, 0.49957152],\n",
       "       [0.41965707, 0.58034293],\n",
       "       [0.65856343, 0.34143657],\n",
       "       [0.17679619, 0.82320381],\n",
       "       [0.28036817, 0.71963183],\n",
       "       [0.212888  , 0.787112  ],\n",
       "       [0.59504016, 0.40495984],\n",
       "       [0.66962234, 0.33037766],\n",
       "       [0.67542521, 0.32457479],\n",
       "       [0.75084154, 0.24915846],\n",
       "       [0.59499318, 0.40500682],\n",
       "       [0.39764518, 0.60235482],\n",
       "       [0.35035025, 0.64964975],\n",
       "       [0.63021694, 0.36978306],\n",
       "       [0.65308506, 0.34691494],\n",
       "       [0.23375729, 0.76624271],\n",
       "       [0.26463101, 0.73536899],\n",
       "       [0.63056219, 0.36943781],\n",
       "       [0.63589256, 0.36410744],\n",
       "       [0.20846275, 0.79153725],\n",
       "       [0.65015374, 0.34984626],\n",
       "       [0.57113976, 0.42886024],\n",
       "       [0.58927948, 0.41072052],\n",
       "       [0.59465956, 0.40534044],\n",
       "       [0.17290118, 0.82709882],\n",
       "       [0.34326979, 0.65673021],\n",
       "       [0.64711118, 0.35288882],\n",
       "       [0.42981519, 0.57018481],\n",
       "       [0.66985942, 0.33014058],\n",
       "       [0.67508318, 0.32491682],\n",
       "       [0.28623464, 0.71376536],\n",
       "       [0.6215024 , 0.3784976 ],\n",
       "       [0.61003765, 0.38996235],\n",
       "       [0.15995151, 0.84004849],\n",
       "       [0.69122979, 0.30877021],\n",
       "       [0.64732931, 0.35267069],\n",
       "       [0.48738604, 0.51261396],\n",
       "       [0.63602169, 0.36397831],\n",
       "       [0.38490873, 0.61509127],\n",
       "       [0.56482428, 0.43517572],\n",
       "       [0.32268797, 0.67731203],\n",
       "       [0.61273549, 0.38726451],\n",
       "       [0.04776939, 0.95223061],\n",
       "       [0.66390513, 0.33609487],\n",
       "       [0.63026391, 0.36973609],\n",
       "       [0.38490873, 0.61509127],\n",
       "       [0.65303687, 0.34696313],\n",
       "       [0.09985576, 0.90014424],\n",
       "       [0.19298948, 0.80701052],\n",
       "       [0.16960441, 0.83039559],\n",
       "       [0.55265088, 0.44734912],\n",
       "       [0.14242501, 0.85757499],\n",
       "       [0.65026016, 0.34973984],\n",
       "       [0.60049418, 0.39950582],\n",
       "       [0.06607374, 0.93392626],\n",
       "       [0.63947302, 0.36052698],\n",
       "       [0.26563615, 0.73436385],\n",
       "       [0.59500885, 0.40499115],\n",
       "       [0.17209908, 0.82790092],\n",
       "       [0.67508318, 0.32491682],\n",
       "       [0.51894576, 0.48105424],\n",
       "       [0.65082241, 0.34917759],\n",
       "       [0.45728106, 0.54271894],\n",
       "       [0.65860727, 0.34139273],\n",
       "       [0.56833588, 0.43166412],\n",
       "       [0.60649446, 0.39350554],\n",
       "       [0.45728106, 0.54271894],\n",
       "       [0.47559305, 0.52440695],\n",
       "       [0.58897586, 0.41102414],\n",
       "       [0.65801335, 0.34198665],\n",
       "       [0.61860106, 0.38139894],\n",
       "       [0.61304848, 0.38695152],\n",
       "       [0.64860191, 0.35139809],\n",
       "       [0.5375036 , 0.4624964 ],\n",
       "       [0.14200938, 0.85799062],\n",
       "       [0.81387864, 0.18612136],\n",
       "       [0.56470286, 0.43529714],\n",
       "       [0.40045439, 0.59954561],\n",
       "       [0.68066032, 0.31933968],\n",
       "       [0.06739748, 0.93260252],\n",
       "       [0.30988942, 0.69011058],\n",
       "       [0.40192064, 0.59807936],\n",
       "       [0.31780102, 0.68219898],\n",
       "       [0.5761662 , 0.4238338 ],\n",
       "       [0.6911096 , 0.3088904 ],\n",
       "       [0.30078544, 0.69921456],\n",
       "       [0.57695318, 0.42304682],\n",
       "       [0.35034118, 0.64965882],\n",
       "       [0.58894913, 0.41105087],\n",
       "       [0.29647013, 0.70352987],\n",
       "       [0.47471486, 0.52528514],\n",
       "       [0.42477191, 0.57522809],\n",
       "       [0.16086992, 0.83913008],\n",
       "       [0.35946058, 0.64053942],\n",
       "       [0.64164962, 0.35835038],\n",
       "       [0.379975  , 0.620025  ],\n",
       "       [0.5769627 , 0.4230373 ],\n",
       "       [0.60096182, 0.39903818],\n",
       "       [0.69393502, 0.30606498],\n",
       "       [0.10906012, 0.89093988],\n",
       "       [0.28617029, 0.71382971],\n",
       "       [0.37323979, 0.62676021],\n",
       "       [0.43398401, 0.56601599],\n",
       "       [0.33711084, 0.66288916],\n",
       "       [0.14508558, 0.85491442],\n",
       "       [0.31756021, 0.68243979],\n",
       "       [0.7117372 , 0.2882628 ],\n",
       "       [0.19637319, 0.80362681],\n",
       "       [0.56201507, 0.43798493],\n",
       "       [0.29746344, 0.70253656],\n",
       "       [0.31967409, 0.68032591],\n",
       "       [0.44200552, 0.55799448],\n",
       "       [0.24076349, 0.75923651],\n",
       "       [0.73638358, 0.26361642],\n",
       "       [0.65860727, 0.34139273],\n",
       "       [0.72199318, 0.27800682],\n",
       "       [0.215219  , 0.784781  ],\n",
       "       [0.47273005, 0.52726995],\n",
       "       [0.62447642, 0.37552358],\n",
       "       [0.62443527, 0.37556473],\n",
       "       [0.31774177, 0.68225823],\n",
       "       [0.68066032, 0.31933968],\n",
       "       [0.5327066 , 0.4672934 ],\n",
       "       [0.61891226, 0.38108774],\n",
       "       [0.60972703, 0.39027297],\n",
       "       [0.18118771, 0.81881229],\n",
       "       [0.64448875, 0.35551125],\n",
       "       [0.60095247, 0.39904753],\n",
       "       [0.13339447, 0.86660553],\n",
       "       [0.60114882, 0.39885118],\n",
       "       [0.09137544, 0.90862456],\n",
       "       [0.5499571 , 0.4500429 ],\n",
       "       [0.62443224, 0.37556776],\n",
       "       [0.26340472, 0.73659528],\n",
       "       [0.16759879, 0.83240121],\n",
       "       [0.31125611, 0.68874389],\n",
       "       [0.72199318, 0.27800682],\n",
       "       [0.54665966, 0.45334034],\n",
       "       [0.67085539, 0.32914461],\n",
       "       [0.81585859, 0.18414141],\n",
       "       [0.71749634, 0.28250366],\n",
       "       [0.43861385, 0.56138615],\n",
       "       [0.35000581, 0.64999419],\n",
       "       [0.47081344, 0.52918656],\n",
       "       [0.61214159, 0.38785841],\n",
       "       [0.61869151, 0.38130849],\n",
       "       [0.74854593, 0.25145407],\n",
       "       [0.13265545, 0.86734455],\n",
       "       [0.34445035, 0.65554965],\n",
       "       [0.22153441, 0.77846559],\n",
       "       [0.13452248, 0.86547752],\n",
       "       [0.26159621, 0.73840379],\n",
       "       [0.47691319, 0.52308681],\n",
       "       [0.28662537, 0.71337463],\n",
       "       [0.4831812 , 0.5168188 ],\n",
       "       [0.54341815, 0.45658185],\n",
       "       [0.65241333, 0.34758667],\n",
       "       [0.62437583, 0.37562417],\n",
       "       [0.3733675 , 0.6266325 ],\n",
       "       [0.64575206, 0.35424794],\n",
       "       [0.68322066, 0.31677934],\n",
       "       [0.80580325, 0.19419675],\n",
       "       [0.69648574, 0.30351426],\n",
       "       [0.32858972, 0.67141028],\n",
       "       [0.06069937, 0.93930063],\n",
       "       [0.45560397, 0.54439603],\n",
       "       [0.64228107, 0.35771893],\n",
       "       [0.16881463, 0.83118537],\n",
       "       [0.29977383, 0.70022617],\n",
       "       [0.19103218, 0.80896782],\n",
       "       [0.61918797, 0.38081203],\n",
       "       [0.2399152 , 0.7600848 ],\n",
       "       [0.52674152, 0.47325848],\n",
       "       [0.70880663, 0.29119337],\n",
       "       [0.59186032, 0.40813968],\n",
       "       [0.40293136, 0.59706864],\n",
       "       [0.27716132, 0.72283868],\n",
       "       [0.11932695, 0.88067305],\n",
       "       [0.58845816, 0.41154184],\n",
       "       [0.36275908, 0.63724092],\n",
       "       [0.28491536, 0.71508464],\n",
       "       [0.61864551, 0.38135449],\n",
       "       [0.67539957, 0.32460043],\n",
       "       [0.53650686, 0.46349314],\n",
       "       [0.6008496 , 0.3991504 ],\n",
       "       [0.0860079 , 0.9139921 ],\n",
       "       [0.79876838, 0.20123162],\n",
       "       [0.72703424, 0.27296576],\n",
       "       [0.38514878, 0.61485122],\n",
       "       [0.23099116, 0.76900884],\n",
       "       [0.58835428, 0.41164572],\n",
       "       [0.68911149, 0.31088851],\n",
       "       [0.74151016, 0.25848984],\n",
       "       [0.29699557, 0.70300443],\n",
       "       [0.5949368 , 0.4050632 ],\n",
       "       [0.10912878, 0.89087122],\n",
       "       [0.59474573, 0.40525427],\n",
       "       [0.31827232, 0.68172768],\n",
       "       [0.68377598, 0.31622402],\n",
       "       [0.17160977, 0.82839023],\n",
       "       [0.63626225, 0.36373775],\n",
       "       [0.60696572, 0.39303428],\n",
       "       [0.26255142, 0.73744858],\n",
       "       [0.21413736, 0.78586264],\n",
       "       [0.28056469, 0.71943531],\n",
       "       [0.38019563, 0.61980437],\n",
       "       [0.07068158, 0.92931842],\n",
       "       [0.04281338, 0.95718662],\n",
       "       [0.64174824, 0.35825176],\n",
       "       [0.13053934, 0.86946066],\n",
       "       [0.44394633, 0.55605367],\n",
       "       [0.18860409, 0.81139591],\n",
       "       [0.1498264 , 0.8501736 ],\n",
       "       [0.0712722 , 0.9287278 ],\n",
       "       [0.48461946, 0.51538054],\n",
       "       [0.2151099 , 0.7848901 ],\n",
       "       [0.49436079, 0.50563921],\n",
       "       [0.15938632, 0.84061368],\n",
       "       [0.52985863, 0.47014137],\n",
       "       [0.71209308, 0.28790692],\n",
       "       [0.35035025, 0.64964975],\n",
       "       [0.30748264, 0.69251736],\n",
       "       [0.72694137, 0.27305863],\n",
       "       [0.22379282, 0.77620718],\n",
       "       [0.25138393, 0.74861607],\n",
       "       [0.59488981, 0.40511019],\n",
       "       [0.5077294 , 0.4922706 ],\n",
       "       [0.1976516 , 0.8023484 ],\n",
       "       [0.59992652, 0.40007348],\n",
       "       [0.2282715 , 0.7717285 ],\n",
       "       [0.63648072, 0.36351928],\n",
       "       [0.40957851, 0.59042149],\n",
       "       [0.30235877, 0.69764123],\n",
       "       [0.4216193 , 0.5783807 ],\n",
       "       [0.2125925 , 0.7874075 ],\n",
       "       [0.23399128, 0.76600872],\n",
       "       [0.70205491, 0.29794509],\n",
       "       [0.60566841, 0.39433159],\n",
       "       [0.61826227, 0.38173773],\n",
       "       [0.38583233, 0.61416767],\n",
       "       [0.3541869 , 0.6458131 ],\n",
       "       [0.68599765, 0.31400235],\n",
       "       [0.6530737 , 0.3469263 ],\n",
       "       [0.36745925, 0.63254075],\n",
       "       [0.44008296, 0.55991704],\n",
       "       [0.53863169, 0.46136831],\n",
       "       [0.62442156, 0.37557844],\n",
       "       [0.58136787, 0.41863213],\n",
       "       [0.61267842, 0.38732158],\n",
       "       [0.10047055, 0.89952945],\n",
       "       [0.58921183, 0.41078817],\n",
       "       [0.37683866, 0.62316134],\n",
       "       [0.40980497, 0.59019503],\n",
       "       [0.60151795, 0.39848205],\n",
       "       [0.61288352, 0.38711648],\n",
       "       [0.14318076, 0.85681924],\n",
       "       [0.64019123, 0.35980877],\n",
       "       [0.58208312, 0.41791688],\n",
       "       [0.79041963, 0.20958037],\n",
       "       [0.2685076 , 0.7314924 ],\n",
       "       [0.3541869 , 0.6458131 ],\n",
       "       [0.67248013, 0.32751987],\n",
       "       [0.45998268, 0.54001732],\n",
       "       [0.70969345, 0.29030655],\n",
       "       [0.15796897, 0.84203103],\n",
       "       [0.77546765, 0.22453235],\n",
       "       [0.35601313, 0.64398687],\n",
       "       [0.16807232, 0.83192768],\n",
       "       [0.40972682, 0.59027318],\n",
       "       [0.18976976, 0.81023024],\n",
       "       [0.69648574, 0.30351426],\n",
       "       [0.37696819, 0.62303181],\n",
       "       [0.64170492, 0.35829508],\n",
       "       [0.28550466, 0.71449534]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba=logit.predict_proba(X_train)\n",
    "\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression on training set: 0.69\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic regression on training set: {:.2f}'.format(logit.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190 103]\n",
      " [ 50 156]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mat=confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive=c_mat[0,1]\n",
    "true_negative=c_mat[0,0]\n",
    "false_negative=c_mat[1,0]\n",
    "true_positive=c_mat[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933867735470942"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare this to what was produced from score method\n",
    "accuracy=((true_negative+true_positive)/len(y_train))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3066132264529058"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-accuracy\n",
    "classification_error=((false_positive+false_negative)/len(y_train))\n",
    "classification_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7572815533980582"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also called true positive rate\n",
    "recall=true_positive/(true_positive+false_negative)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6023166023166023"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision=true_positive/(true_positive+false_positive)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6797990778573303"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score=(recall+precision)/2\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3515358361774744"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate=false_positive/(false_positive+true_negative)\n",
    "false_positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=(classification_report(y_train,y_pred,output_dict=True))\n",
    "#print(cr[\"0\"])\n",
    "#print(cr[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set: 0.67\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on test set: {:.2f}'.format(logit.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba=[i[1] for i in y_pred_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEc1JREFUeJzt3X+s3Xddx/Hnq7d30OGgk14T6I91YplU0BRv5hISAUUpM6wTpnbJIiSTZSrwh7g4AkGdGpAlosZqHITwQ9mci5mFFJuIIyihuLvsFxupljrpXYmr2GHiCrvr3v5xzrqz29ve77079/T0s+cjuen3+z2f+/2++v2evvq93+8596SqkCS1adWZDiBJWjmWvCQ1zJKXpIZZ8pLUMEtekhpmyUtSwyx5SWqYJS9JDbPkJalhq8/UhtetW1ebN28+U5uXpLPSXXfd9d9VNdV1/Bkr+c2bNzMzM3OmNi9JZ6Uk/7mU8V6ukaSGWfKS1DBLXpIaZslLUsMseUlqmCUvSQ2z5CWpYYuWfJKPJ3kkyddO8XiS/GmSA0nuS/Lq4ceUJC1HlzdDfQL4M+BTp3j8TcCW/tdPAH/R/1Mamvfffj83f/UQx5fwmcTPW72K6QvW8uVv/M8zlk+ugrknh51wdF5wzgT/9/jxkWxrFTDMXXXVJZsA+Ot932TUny4d4Nz+vptITvtcWgW86NxJjj42R2DJWddMrmJV8ozjdP65k/z2m3+Ey7etX078ZVu05KvqS0k2n2bIDuBT1ftE8H1J1iZ5SVV9a0gZ9Rz3/tvv56/2fXPJ3/e9J548qeDh7C54YGQFD8MteGBZx3FYiqf33WInC08CRx+bO/F9S3VsgSfZ0cfmuO62ewFGWvTDuCa/Hjg0MD/bXyYNxc1fPbT4IOksMHe8uHHv/pFucxglnwWWLfifX5JrkswkmTly5MgQNq3ngqVcopHG3eFHj410e8Mo+Vlg48D8BuDwQgOr6qaqmq6q6ampzr9ETc9xE1noPEI6O7107ZqRbm8YJb8b+OX+q2wuAb7j9XgN05U/sXHxQdJZYHIiXPfGi0a6zS4vobwZ+ApwUZLZJFcnuTbJtf0he4CDwAHgo8CvrVhaPSf9/uWv4qpLNi35jP55q1fxmpd9/0nLJ8/yd4e84JyJkW1r2Lvqqks2cdUlmxa8xrvSwtP7brHn0ip6r4Z56vuWas3kqpOO0/nnTnLjFT828lfXpM7Q9c7p6eny98lL0tIkuauqpruOP8vPaSRJp2PJS1LDLHlJapglL0kNs+QlqWGWvCQ1zJKXpIZZ8pLUMEtekhpmyUtSwyx5SWqYJS9JDbPkJalhlrwkNcySl6SGWfKS1DBLXpIaZslLUsMseUlqmCUvSQ2z5CWpYZa8JDXMkpekhlnyktQwS16SGmbJS1LDLHlJapglL0kNs+QlqWGWvCQ1rFPJJ9meZH+SA0muX+DxTUnuSHJ3kvuSXDr8qJKkpVq05JNMALuANwFbgSuTbJ037P3ArVW1DdgJ/Pmwg0qSlq7LmfzFwIGqOlhVjwO3ADvmjSnghf3pFwGHhxdRkrRcXUp+PXBoYH62v2zQ7wBXJZkF9gDvWmhFSa5JMpNk5siRI8uIK0laii4lnwWW1bz5K4FPVNUG4FLg00lOWndV3VRV01U1PTU1tfS0kqQl6VLys8DGgfkNnHw55mrgVoCq+grwfGDdMAJKkpavS8nfCWxJcmGSc+jdWN09b8w3gZ8GSPIKeiXv9RhJOsMWLfmqegJ4J7AX+Dq9V9E8kOSGJJf1h70HeEeSe4GbgbdX1fxLOpKkEVvdZVBV7aF3Q3Vw2QcGph8EXjPcaJKkZ8t3vEpSwyx5SWqYJS9JDbPkJalhlrwkNcySl6SGWfKS1DBLXpIaZslLUsMseUlqmCUvSQ2z5CWpYZa8JDXMkpekhlnyktQwS16SGmbJS1LDLHlJapglL0kNs+QlqWGWvCQ1zJKXpIZZ8pLUMEtekhpmyUtSwyx5SWqYJS9JDbPkJalhlrwkNaxTySfZnmR/kgNJrj/FmF9M8mCSB5J8ZrgxJUnLsXqxAUkmgF3AzwCzwJ1JdlfVgwNjtgDvBV5TVUeT/MBKBZYkddflTP5i4EBVHayqx4FbgB3zxrwD2FVVRwGq6pHhxpQkLUeXkl8PHBqYn+0vG/Ry4OVJvpxkX5LtwwooSVq+RS/XAFlgWS2wni3A64ANwD8neWVVPfqMFSXXANcAbNq0aclhJUlL0+VMfhbYODC/ATi8wJi/r6q5qvoPYD+90n+Gqrqpqqaranpqamq5mSVJHXUp+TuBLUkuTHIOsBPYPW/M7cDrAZKso3f55uAwg0qSlm7Rkq+qJ4B3AnuBrwO3VtUDSW5Icll/2F7g20keBO4Arquqb69UaElSN6maf3l9NKanp2tmZuaMbFuSzlZJ7qqq6a7jfcerJDXMkpekhlnyktQwS16SGmbJS1LDLHlJapglL0kNs+QlqWGWvCQ1zJKXpIZZ8pLUMEtekhpmyUtSwyx5SWqYJS9JDbPkJalhlrwkNcySl6SGWfKS1DBLXpIaZslLUsMseUlqmCUvSQ2z5CWpYZa8JDXMkpekhlnyktQwS16SGmbJS1LDLHlJalinkk+yPcn+JAeSXH+acVckqSTTw4soSVquRUs+yQSwC3gTsBW4MsnWBcadB7wb+OqwQ0qSlqfLmfzFwIGqOlhVjwO3ADsWGPd7wIeB7w4xnyTpWehS8uuBQwPzs/1lJyTZBmysqs+dbkVJrkkyk2TmyJEjSw4rSVqaLiWfBZbViQeTVcBHgPcstqKquqmqpqtqempqqntKSdKydCn5WWDjwPwG4PDA/HnAK4EvJnkIuATY7c1XSTrzupT8ncCWJBcmOQfYCex+6sGq+k5VrauqzVW1GdgHXFZVMyuSWJLU2aIlX1VPAO8E9gJfB26tqgeS3JDkspUOKElavtVdBlXVHmDPvGUfOMXY1z37WJKkYfAdr5LUMEtekhpmyUtSwyx5SWqYJS9JDbPkJalhlrwkNcySl6SGWfKS1DBLXpIaZslLUsMseUlqmCUvSQ2z5CWpYZa8JDXMkpekhlnyktQwS16SGmbJS1LDLHlJapglL0kNs+QlqWGWvCQ1zJKXpIZZ8pLUMEtekhpmyUtSwyx5SWqYJS9JDetU8km2J9mf5ECS6xd4/DeSPJjkviRfSHLB8KNKkpZq0ZJPMgHsAt4EbAWuTLJ13rC7gemq+lHgNuDDww4qSVq6LmfyFwMHqupgVT0O3ALsGBxQVXdU1WP92X3AhuHGlCQtR5eSXw8cGpif7S87lauBzz+bUJKk4VjdYUwWWFYLDkyuAqaB157i8WuAawA2bdrUMaIkabm6nMnPAhsH5jcAh+cPSvIG4H3AZVX1vYVWVFU3VdV0VU1PTU0tJ68kaQm6lPydwJYkFyY5B9gJ7B4ckGQb8Jf0Cv6R4ceUJC3HoiVfVU8A7wT2Al8Hbq2qB5LckOSy/rAbge8D/jbJPUl2n2J1kqQR6nJNnqraA+yZt+wDA9NvGHIuSdIQ+I5XSWqYJS9JDbPkJalhlrwkNcySl6SGWfKS1DBLXpIaZslLUsMseUlqmCUvSQ2z5CWpYZa8JDXMkpekhlnyktQwS16SGmbJS1LDLHlJapglL0kNs+QlqWGWvCQ1zJKXpIZZ8pLUMEtekhpmyUtSwyx5SWqYJS9JDbPkJalhlrwkNcySl6SGWfKS1LDVXQYl2Q78CTABfKyqPjTv8ecBnwJ+HPg28EtV9dBwo57s9rsf5nc/+wBHH5sDYM3kKp4/OcHRx+aYSDhexfq1a9j84jXsO3iU41UnvnftmkkSePSxOV66dg3XvfEiLt+2/hnrvnHvfh5+9NhK/zWaE6AWHbV06xc4TpJOb9GSTzIB7AJ+BpgF7kyyu6oeHBh2NXC0qn4oyU7gD4FfWonAT7n97oe57rZ7mTv+dJ0cm3uSY3NPApwo9IcfPbZgUT96bO7E9MOPHuO9f3c/AJdvW8/tdz/Me//ufo7NHV/Jv0KzVqLg4eTjJGlxXS7XXAwcqKqDVfU4cAuwY96YHcAn+9O3AT+dJMOLebIb9+5/RsE/W8fmjnPj3v0n1m3Bj6fB4yRpcV1Kfj1waGB+tr9swTFV9QTwHeDF81eU5JokM0lmjhw5srzEfYdX4DLKU+tciXVreDw+UnddSn6hM/L5p9BdxlBVN1XVdFVNT01Ndcl3Si9du+ZZff/p1rkS69bweHyk7rqU/CywcWB+A3D4VGOSrAZeBPzPMAKeynVvvIjJieFdEVozOcF1b7zoxLrXTE4Mbd0ansHjJGlxXUr+TmBLkguTnAPsBHbPG7MbeFt/+grgn6pqpe6/Ab0bbzde8WOcf+7kiWVrJledmJ/o3xJYv3YNr3nZ95+Yf8raNZOcf+4k6Y/54FtedeJm3uXb1vPBt7yK9Z4xLstK3YyZf5wkLS5dujjJpcAf03sJ5cer6g+S3ADMVNXuJM8HPg1so3cGv7OqDp5undPT0zUzM/Os/wKS9FyS5K6qmu46vtPr5KtqD7Bn3rIPDEx/F/iFrhuVJI2G73iVpIZZ8pLUMEtekhpmyUtSwyx5SWqYJS9JDbPkJalhnd4MtSIbTo4A/7nCm1kH/PcKb2M5xjUXjG+2cc0F45ttXHPB+GYb11zwdLYLqqrzL/86YyU/CklmlvLOsFEZ11wwvtnGNReMb7ZxzQXjm21cc8Hys3m5RpIaZslLUsNaL/mbznSAUxjXXDC+2cY1F4xvtnHNBeObbVxzwTKzNX1NXpKe61o/k5ek57QmSj7J9iT7kxxIcv0Cj/9GkgeT3JfkC0kuGJNc1ya5P8k9Sf4lydZR5OqSbWDcFUkqyUhecdBhn709yZH+Prsnya+MQ67+mF/sP88eSPKZUeTqki3JRwb2178leXRMcm1KckeSu/v/Ni8dRa6O2S7od8V9Sb6YZMOIcn08ySNJvnaKx5PkT/u570vy6kVXWlVn9Re9DzL5BvCDwDnAvcDWeWNeD5zbn/5V4G/GJNcLB6YvA/5hXPZZf9x5wJeAfcD0OOQC3g782Rg+x7YAdwPn9+d/YFyyzRv/Lnof/HPGc9G7xvyr/emtwEPjss+AvwXe1p/+KeDTI8r2k8Crga+d4vFLgc/T+wC2S4CvLrbOFs7kLwYOVNXBqnocuAXYMTigqu6oqsf6s/vofU7tOOT634HZF7DAh5+fqWx9vwd8GPjumOUatS653gHsqqqjAFX1yBhlG3QlcPOY5Crghf3pF3HyZ0efyWxbgS/0p+9Y4PEVUVVf4vSfj70D+FT17APWJnnJ6dbZQsmvBw4NzM/2l53K1fT+J1xpnXIl+fUk36BXpu8eQa5O2ZJsAzZW1edGlKlTrr639n9UvS3JxgUePxO5Xg68PMmXk+xLsn0EubpmA3qXIIALgX8ak1y/A1yVZJbeJ8+9awS5oFu2e4G39qd/HjgvyYtHkG0xS+27Jkp+oc+NXvCMOMlVwDRw44om6m9ugWUn5aqqXVX1MuC3gPeveKqe02ZLsgr4CPCeEeU5sekFls3fZ58FNlfVjwL/CHxyxVN1y7Wa3iWb19E7W/5YkrUrnAuW8PwHdgK3VdXxFczzlC65rgQ+UVUb6F2G+HT/ubfSumT7TeC1Se4GXgs8DDyx0sE6WMrxBtoo+Vlg8GxuAwv82JfkDcD7gMuq6nvjkmvALcDlK5roaYtlOw94JfDFJA/Ru/a3ewQ3XxfdZ1X17YHj91Hgx1c4U6dc/TF/X1VzVfUfwH56pT8O2Z6yk9FcqoFuua4GbgWoqq8Az6f3+1nOeLaqOlxVb6mqbfR6g6r6zgiyLWapvdLEjdfVwEF6P4Y+dRPlR+aN2UbvRsuWMcu1ZWD6zcDMuGSbN/6LjObGa5d99pKB6Z8H9o1Jru3AJ/vT6+j9SP3iccjWH3cR8BD998aMQy56l03f3p9+Rb+sVjxfx2zrgFX96T8AbhjFfutvbzOnvvH6czzzxuu/Lrq+UQVf4Z1yKfBv/SJ/X3/ZDfTO2qH3Y/1/Aff0v3aPSa4/AR7oZ7rjdEU76mzzxo6k5Dvusw/299m9/X32w2OSK8AfAQ8C9wM7x+lY0rv+/aFRZeq4z7YCX+4fy3uAnx2jbFcA/94f8zHgeSPKdTPwLWCO3ln71cC1wLUDz7Nd/dz3d/l36TteJalhLVyTlySdgiUvSQ2z5CWpYZa8JDXMkpekhlnyktQwS16SGmbJS1LD/h9ySybOc+1tcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "ax.scatter(y_pred_proba,y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's us a decision tree to solve a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydataset import data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris=data('iris')\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.columns=[col.lower().replace('.','_') for col in df_iris]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.head()\n",
    "X=df_iris.drop(['species'],axis=1)\n",
    "y=df_iris[['species']]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.5  , 0.5  ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.5  , 0.5  ],\n",
       "       [0.   , 0.   , 1.   ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(X_train)\n",
    "y_pred_proba=clf.predict_proba(X_train)\n",
    "y_pred_proba\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32,  0,  0],\n",
       "       [ 0, 40,  0],\n",
       "       [ 0,  2, 31]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the confusion matrix \"pretty\"\n",
    "labels=sorted(y_train.species.unique())\n",
    "pretty_cr=pd.DataFrame(confusion_matrix(y_train,y_pred),index=labels,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
